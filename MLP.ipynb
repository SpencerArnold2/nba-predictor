{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spencer/Desktop/Repos/nba-predictor/preprocessing.py:43: FutureWarning: Dropping of nuisance columns in rolling operations is deprecated; in a future version this will raise TypeError. Select only valid columns before calling the operation. Dropped columns were Index(['matchup', 'team_abbreviation', 'team_name', 'wl'], dtype='object')\n",
      "  rolling_averages = grouped[columns_to_average].apply(lambda x: x.rolling(window=len(x), min_periods=1).mean().shift(1))\n",
      "/Users/spencer/Desktop/Repos/nba-predictor/preprocessing.py:43: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  rolling_averages = grouped[columns_to_average].apply(lambda x: x.rolling(window=len(x), min_periods=1).mean().shift(1))\n",
      "/Users/spencer/Desktop/Repos/nba-predictor/preprocessing.py:62: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('_y$', '')\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "data_path = \"data/game.csv\"\n",
    "X_train, X_test, y_train, y_test = prep_all(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.values.reshape(-1, 1, 135)  # Reshape to (32520, 1, 136)\n",
    "X_test = X_test.values.reshape(-1, 1, 135)    # Reshape to (N, 1, 136), where N is the number of test samples\n",
    "\n",
    "train_data = TensorDataset(torch.tensor(X_train), torch.tensor(y_train.to_numpy()))\n",
    "test_data = TensorDataset(torch.tensor(X_test), torch.tensor(y_test.to_numpy()))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[2]  # The number of features in your preprocessed data\n",
    "hidden_size1 = 64\n",
    "hidden_size2 = 32\n",
    "output_size = 2  # Win or loss (binary classification)\n",
    "\n",
    "model = MLPModel(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.5668, Validation Acc: 65.07%\n",
      "Epoch [2/50], Loss: 0.5636, Validation Acc: 64.65%\n",
      "Epoch [3/50], Loss: 0.5287, Validation Acc: 65.45%\n",
      "Epoch [4/50], Loss: 0.5846, Validation Acc: 65.04%\n",
      "Epoch [5/50], Loss: 0.5113, Validation Acc: 65.27%\n",
      "Epoch [6/50], Loss: 0.5086, Validation Acc: 65.20%\n",
      "Epoch [7/50], Loss: 0.4475, Validation Acc: 65.16%\n",
      "Epoch [8/50], Loss: 0.6149, Validation Acc: 65.14%\n",
      "Epoch [9/50], Loss: 0.6208, Validation Acc: 64.35%\n",
      "Epoch [10/50], Loss: 0.6565, Validation Acc: 65.40%\n",
      "Epoch [11/50], Loss: 0.4662, Validation Acc: 65.14%\n",
      "Epoch [12/50], Loss: 0.5606, Validation Acc: 65.05%\n",
      "Epoch [13/50], Loss: 0.5088, Validation Acc: 64.82%\n",
      "Epoch [14/50], Loss: 0.5310, Validation Acc: 65.12%\n",
      "Epoch [15/50], Loss: 0.5331, Validation Acc: 65.05%\n",
      "Epoch [16/50], Loss: 0.4471, Validation Acc: 64.94%\n",
      "Epoch [17/50], Loss: 0.6024, Validation Acc: 64.81%\n",
      "Epoch [18/50], Loss: 0.5908, Validation Acc: 65.26%\n",
      "Epoch [19/50], Loss: 0.4599, Validation Acc: 64.05%\n",
      "Epoch [20/50], Loss: 0.5367, Validation Acc: 65.34%\n",
      "Epoch [21/50], Loss: 0.4380, Validation Acc: 64.91%\n",
      "Epoch [22/50], Loss: 0.5147, Validation Acc: 65.26%\n",
      "Epoch [23/50], Loss: 0.5632, Validation Acc: 65.05%\n",
      "Epoch [24/50], Loss: 0.5262, Validation Acc: 65.22%\n",
      "Epoch [25/50], Loss: 0.4747, Validation Acc: 65.47%\n",
      "Epoch [26/50], Loss: 0.5238, Validation Acc: 64.62%\n",
      "Epoch [27/50], Loss: 0.4478, Validation Acc: 65.22%\n",
      "Epoch [28/50], Loss: 0.4228, Validation Acc: 64.56%\n",
      "Epoch [29/50], Loss: 0.6605, Validation Acc: 65.05%\n",
      "Epoch [30/50], Loss: 0.5163, Validation Acc: 65.24%\n",
      "Epoch [31/50], Loss: 0.4910, Validation Acc: 64.97%\n",
      "Epoch [32/50], Loss: 0.5197, Validation Acc: 64.67%\n",
      "Epoch [33/50], Loss: 0.5179, Validation Acc: 65.49%\n",
      "Epoch [34/50], Loss: 0.4810, Validation Acc: 64.39%\n",
      "Epoch [35/50], Loss: 0.5351, Validation Acc: 65.00%\n",
      "Epoch [36/50], Loss: 0.5007, Validation Acc: 64.81%\n",
      "Epoch [37/50], Loss: 0.4763, Validation Acc: 65.11%\n",
      "Epoch [38/50], Loss: 0.5120, Validation Acc: 65.26%\n",
      "Epoch [39/50], Loss: 0.5989, Validation Acc: 65.20%\n",
      "Epoch [40/50], Loss: 0.5729, Validation Acc: 64.37%\n",
      "Epoch [41/50], Loss: 0.4710, Validation Acc: 64.90%\n",
      "Epoch [42/50], Loss: 0.4937, Validation Acc: 65.04%\n",
      "Epoch [43/50], Loss: 0.5092, Validation Acc: 64.94%\n",
      "Epoch [44/50], Loss: 0.4654, Validation Acc: 64.29%\n",
      "Epoch [45/50], Loss: 0.6899, Validation Acc: 64.44%\n",
      "Epoch [46/50], Loss: 0.4448, Validation Acc: 64.97%\n",
      "Epoch [47/50], Loss: 0.6141, Validation Acc: 64.94%\n",
      "Epoch [48/50], Loss: 0.4805, Validation Acc: 64.52%\n",
      "Epoch [49/50], Loss: 0.4826, Validation Acc: 64.91%\n",
      "Epoch [50/50], Loss: 0.4720, Validation Acc: 65.21%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "total_loss = []\n",
    "acc = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.squeeze(1).float(), labels.long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.squeeze(1).float(), labels.long()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        total_loss.append(loss.item())\n",
    "        acc.append(100 * correct / total)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Acc: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.21%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in valid_loader:\n",
    "        inputs, labels = inputs.squeeze(1).float(), labels.long()\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Export to ONNX\n",
    "# example_input = torch.tensor(X_train[0]).float()  # Take a sample input from your dataset\n",
    "# example_input = example_input.to(model.fc1.weight.dtype)\n",
    "\n",
    "# torch.onnx.export(\n",
    "#     model,\n",
    "#     example_input,\n",
    "#     \"models/MLP.onnx\",\n",
    "#     input_names=[\"input\"],\n",
    "#     output_names=[\"output\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # define the hyperparameters to tune\n",
    "    input_size = X_train.shape[2]\n",
    "    hidden_size1 = trial.suggest_int(\"hidden_size1\", 16, 128, log=True)\n",
    "    hidden_size2 = trial.suggest_int(\"hidden_size2\", 16, 128, log=True)\n",
    "    output_size = 2\n",
    "\n",
    "    # create the model with the given hyperparameters\n",
    "    model = MLPModel(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "    # define the optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_epochs = 50\n",
    "    # train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.squeeze(1).float(), labels.long()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for inputs, labels in valid_loader:\n",
    "                inputs, labels = inputs.squeeze(1).float(), labels.long()\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            trial.report(100 * correct / total, epoch)\n",
    "\n",
    "            # early stopping\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-03 02:33:04,456]\u001b[0m A new study created in memory with name: no-name-c09d6e7b-6910-40e0-bbf7-96afb0db48ae\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:34:10,842]\u001b[0m Trial 0 finished with value: 63.838283004741704 and parameters: {'hidden_size1': 94, 'hidden_size2': 19, 'lr': 0.00705872930557031}. Best is trial 0 with value: 63.838283004741704.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:35:23,137]\u001b[0m Trial 1 finished with value: 61.330172198652356 and parameters: {'hidden_size1': 80, 'hidden_size2': 51, 'lr': 0.002638216011292618}. Best is trial 0 with value: 63.838283004741704.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:36:30,397]\u001b[0m Trial 2 finished with value: 61.84177689044173 and parameters: {'hidden_size1': 30, 'hidden_size2': 58, 'lr': 0.002658352821377608}. Best is trial 0 with value: 63.838283004741704.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:37:53,079]\u001b[0m Trial 3 finished with value: 61.15547791365111 and parameters: {'hidden_size1': 84, 'hidden_size2': 26, 'lr': 0.0007860723359471324}. Best is trial 0 with value: 63.838283004741704.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:39:36,250]\u001b[0m Trial 4 finished with value: 64.21262790117295 and parameters: {'hidden_size1': 26, 'hidden_size2': 117, 'lr': 0.0005369825477176465}. Best is trial 4 with value: 64.21262790117295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:39:38,885]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:39:41,214]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:39:43,372]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:41:34,602]\u001b[0m Trial 8 finished with value: 63.07711504866484 and parameters: {'hidden_size1': 127, 'hidden_size2': 31, 'lr': 0.00033600212229582105}. Best is trial 4 with value: 64.21262790117295.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:42:59,577]\u001b[0m Trial 9 finished with value: 64.94883953082106 and parameters: {'hidden_size1': 24, 'hidden_size2': 106, 'lr': 0.009644997983371349}. Best is trial 9 with value: 64.94883953082106.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:43:00,749]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:44:11,064]\u001b[0m Trial 11 finished with value: 62.740204641876716 and parameters: {'hidden_size1': 30, 'hidden_size2': 122, 'lr': 0.0006530456553841126}. Best is trial 9 with value: 64.94883953082106.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:44:12,156]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:44:13,381]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:45:18,799]\u001b[0m Trial 14 finished with value: 64.83653606189169 and parameters: {'hidden_size1': 22, 'hidden_size2': 106, 'lr': 0.0004570806819989727}. Best is trial 9 with value: 64.94883953082106.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:45:19,654]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:46:54,167]\u001b[0m Trial 16 finished with value: 65.95957075118542 and parameters: {'hidden_size1': 16, 'hidden_size2': 96, 'lr': 0.00948339410148986}. Best is trial 16 with value: 65.95957075118542.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:46:55,904]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:46:57,788]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:47:00,607]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:47:02,626]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:48:46,843]\u001b[0m Trial 21 finished with value: 62.378337908659844 and parameters: {'hidden_size1': 23, 'hidden_size2': 103, 'lr': 0.002853536365012944}. Best is trial 16 with value: 65.95957075118542.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:48:48,489]\u001b[0m Trial 22 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:48:49,993]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:48:51,754]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:48:52,862]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:48:54,832]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:49:38,228]\u001b[0m Trial 27 finished with value: 64.26254055403045 and parameters: {'hidden_size1': 16, 'hidden_size2': 83, 'lr': 0.0017436721808775483}. Best is trial 16 with value: 65.95957075118542.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:50:33,900]\u001b[0m Trial 28 finished with value: 63.48889443473921 and parameters: {'hidden_size1': 34, 'hidden_size2': 57, 'lr': 0.0008816117803189397}. Best is trial 16 with value: 65.95957075118542.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:50:35,022]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:50:35,879]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:50:36,707]\u001b[0m Trial 31 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:50:37,846]\u001b[0m Trial 32 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:51:19,661]\u001b[0m Trial 33 finished with value: 63.46393810831046 and parameters: {'hidden_size1': 16, 'hidden_size2': 83, 'lr': 0.003467014286585603}. Best is trial 16 with value: 65.95957075118542.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:51:20,772]\u001b[0m Trial 34 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:51:21,830]\u001b[0m Trial 35 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:51:22,707]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:51:23,804]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:51:24,829]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:51:25,731]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:51:27,207]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:52:56,423]\u001b[0m Trial 41 finished with value: 63.90067382081357 and parameters: {'hidden_size1': 17, 'hidden_size2': 119, 'lr': 0.0007279054738328149}. Best is trial 16 with value: 65.95957075118542.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:52:59,005]\u001b[0m Trial 42 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:53:01,713]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:53:04,287]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:53:06,280]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:53:09,017]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:55:19,897]\u001b[0m Trial 47 finished with value: 64.25006239081607 and parameters: {'hidden_size1': 27, 'hidden_size2': 97, 'lr': 0.0006353804390989581}. Best is trial 16 with value: 65.95957075118542.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:55:21,590]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:55:22,823]\u001b[0m Trial 49 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:57:41,992]\u001b[0m Trial 50 finished with value: 63.30172198652358 and parameters: {'hidden_size1': 23, 'hidden_size2': 96, 'lr': 0.0014423600313312644}. Best is trial 16 with value: 65.95957075118542.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:57:44,620]\u001b[0m Trial 51 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:57:47,207]\u001b[0m Trial 52 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:57:50,001]\u001b[0m Trial 53 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:57:52,985]\u001b[0m Trial 54 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:57:55,849]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:57:58,847]\u001b[0m Trial 56 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:58:01,408]\u001b[0m Trial 57 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:58:04,603]\u001b[0m Trial 58 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:58:07,596]\u001b[0m Trial 59 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:58:10,470]\u001b[0m Trial 60 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 02:58:13,043]\u001b[0m Trial 61 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:13,694]\u001b[0m Trial 62 finished with value: 64.51210381831794 and parameters: {'hidden_size1': 17, 'hidden_size2': 97, 'lr': 0.0007342594672156109}. Best is trial 16 with value: 65.95957075118542.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:17,415]\u001b[0m Trial 63 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:21,532]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:23,989]\u001b[0m Trial 65 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:27,731]\u001b[0m Trial 66 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:31,927]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:35,686]\u001b[0m Trial 68 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:39,575]\u001b[0m Trial 69 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:43,703]\u001b[0m Trial 70 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:47,427]\u001b[0m Trial 71 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:50,816]\u001b[0m Trial 72 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:54,772]\u001b[0m Trial 73 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:00:59,101]\u001b[0m Trial 74 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:01:03,046]\u001b[0m Trial 75 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:01:07,791]\u001b[0m Trial 76 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:01:12,221]\u001b[0m Trial 77 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:01:16,224]\u001b[0m Trial 78 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:01:23,511]\u001b[0m Trial 79 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:01:27,994]\u001b[0m Trial 80 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:01:31,811]\u001b[0m Trial 81 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:01:36,411]\u001b[0m Trial 82 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:01:39,067]\u001b[0m Trial 83 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:01:43,510]\u001b[0m Trial 84 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:01:47,516]\u001b[0m Trial 85 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:01:50,065]\u001b[0m Trial 86 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:04:12,586]\u001b[0m Trial 87 finished with value: 65.26079361118043 and parameters: {'hidden_size1': 31, 'hidden_size2': 35, 'lr': 0.006447463454193406}. Best is trial 16 with value: 65.95957075118542.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:04:17,530]\u001b[0m Trial 88 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:04:20,542]\u001b[0m Trial 89 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:04:25,608]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:04:28,330]\u001b[0m Trial 91 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:04:33,300]\u001b[0m Trial 92 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:04:38,065]\u001b[0m Trial 93 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:04:42,427]\u001b[0m Trial 94 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:04:45,653]\u001b[0m Trial 95 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:04:51,031]\u001b[0m Trial 96 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:04:55,195]\u001b[0m Trial 97 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:04:58,605]\u001b[0m Trial 98 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-03 03:05:02,569]\u001b[0m Trial 99 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'hidden_size1': 16, 'hidden_size2': 96, 'lr': 0.00948339410148986}\n",
      "Best validation accuracy:  65.95957075118542\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# print the best hyperparameters and the best validation accuracy\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best validation accuracy: \", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[2]  # The number of features in your preprocessed data\n",
    "hidden_size1 = 16\n",
    "hidden_size2 = 96\n",
    "output_size = 2  # Win or loss (binary classification)\n",
    "\n",
    "model = MLPModel(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00948339410148986)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.6311, Validation Acc: 64.74%\n",
      "Epoch [2/50], Loss: 0.4440, Validation Acc: 64.76%\n",
      "Epoch [3/50], Loss: 0.5627, Validation Acc: 65.05%\n",
      "Epoch [4/50], Loss: 0.4774, Validation Acc: 64.70%\n",
      "Epoch [5/50], Loss: 0.3900, Validation Acc: 64.60%\n",
      "Epoch [6/50], Loss: 0.4982, Validation Acc: 64.94%\n",
      "Epoch [7/50], Loss: 0.5794, Validation Acc: 65.04%\n",
      "Epoch [8/50], Loss: 0.4394, Validation Acc: 65.22%\n",
      "Epoch [9/50], Loss: 0.5021, Validation Acc: 65.16%\n",
      "Epoch [10/50], Loss: 0.5572, Validation Acc: 65.07%\n",
      "Epoch [11/50], Loss: 0.5900, Validation Acc: 64.81%\n",
      "Epoch [12/50], Loss: 0.5473, Validation Acc: 65.04%\n",
      "Epoch [13/50], Loss: 0.5668, Validation Acc: 65.21%\n",
      "Epoch [14/50], Loss: 0.4651, Validation Acc: 64.86%\n",
      "Epoch [15/50], Loss: 0.4718, Validation Acc: 64.64%\n",
      "Epoch [16/50], Loss: 0.4877, Validation Acc: 64.89%\n",
      "Epoch [17/50], Loss: 0.5014, Validation Acc: 65.11%\n",
      "Epoch [18/50], Loss: 0.5274, Validation Acc: 65.21%\n",
      "Epoch [19/50], Loss: 0.5068, Validation Acc: 65.17%\n",
      "Epoch [20/50], Loss: 0.5106, Validation Acc: 65.20%\n",
      "Epoch [21/50], Loss: 0.5666, Validation Acc: 64.45%\n",
      "Epoch [22/50], Loss: 0.4703, Validation Acc: 65.19%\n",
      "Epoch [23/50], Loss: 0.5158, Validation Acc: 65.01%\n",
      "Epoch [24/50], Loss: 0.5303, Validation Acc: 65.07%\n",
      "Epoch [25/50], Loss: 0.4705, Validation Acc: 64.90%\n",
      "Epoch [26/50], Loss: 0.6013, Validation Acc: 64.39%\n",
      "Epoch [27/50], Loss: 0.3845, Validation Acc: 64.84%\n",
      "Epoch [28/50], Loss: 0.5253, Validation Acc: 64.80%\n",
      "Epoch [29/50], Loss: 0.5097, Validation Acc: 64.80%\n",
      "Epoch [30/50], Loss: 0.5755, Validation Acc: 65.02%\n",
      "Epoch [31/50], Loss: 0.5594, Validation Acc: 65.01%\n",
      "Epoch [32/50], Loss: 0.4162, Validation Acc: 64.86%\n",
      "Epoch [33/50], Loss: 0.6167, Validation Acc: 65.25%\n",
      "Epoch [34/50], Loss: 0.5323, Validation Acc: 64.85%\n",
      "Epoch [35/50], Loss: 0.5368, Validation Acc: 64.30%\n",
      "Epoch [36/50], Loss: 0.5034, Validation Acc: 64.91%\n",
      "Epoch [37/50], Loss: 0.3936, Validation Acc: 65.37%\n",
      "Epoch [38/50], Loss: 0.5080, Validation Acc: 64.75%\n",
      "Epoch [39/50], Loss: 0.5573, Validation Acc: 64.80%\n",
      "Epoch [40/50], Loss: 0.4855, Validation Acc: 64.99%\n",
      "Epoch [41/50], Loss: 0.4512, Validation Acc: 65.19%\n",
      "Epoch [42/50], Loss: 0.4853, Validation Acc: 64.80%\n",
      "Epoch [43/50], Loss: 0.5412, Validation Acc: 64.81%\n",
      "Epoch [44/50], Loss: 0.4249, Validation Acc: 64.57%\n",
      "Epoch [45/50], Loss: 0.4943, Validation Acc: 64.77%\n",
      "Epoch [46/50], Loss: 0.5261, Validation Acc: 64.95%\n",
      "Epoch [47/50], Loss: 0.4890, Validation Acc: 64.92%\n",
      "Epoch [48/50], Loss: 0.5764, Validation Acc: 65.10%\n",
      "Epoch [49/50], Loss: 0.5530, Validation Acc: 64.81%\n",
      "Epoch [50/50], Loss: 0.5320, Validation Acc: 65.00%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "total_loss = []\n",
    "acc = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.squeeze(1).float(), labels.long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.squeeze(1).float(), labels.long()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        total_loss.append(loss.item())\n",
    "        acc.append(100 * correct / total)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Acc: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
